# **Resource efficiency**

Проект для расчета эффективности машин - техники . 
В проекте применяются данные из БД Примавера по фактически выполненным работам или features и сравниваются с реальными данными работы двигателя снятыми с датчиков или target.
Далее все данные подаются в нейросеть и нейросеть предсказывает следующее значение работы двигателя.

План проекта:
1. Данные загружаются из разных источников, все данные хранятся в папке "\data\". Далее внутри папок идет следующая структура:
	- Загруженные из внешних источников данные хранятся в папке "\data\1. external\"
		+ Features - загруженные из БД Примавера данные хранятся в папке "\data\1. external\Primavera_features\" 
		+ Target - загруженные из БД "db_track_torch" данные хранятся в папке "\data\1. external\Omnicomm_target\"
	- предобработанные данные (это данные очищенные от шума, выбросов, сглаженные, сгруппированные по признаку) хранятся в папке "\data\2. preprocessed\"
	- данные для подачи в нейросеть хранятся в папке "\data\3. final\"
	
1. ДОПОЛНИТЬ: разные скрипты преобразования features и target - усреднение, округление и т.д. хранятся в папке  "\script\2. preprocess\"	
1. Далее данные приводятся в один датафрейм в папку "\data\3. final\". Скриптом "\script\2. preprocessed\func_craete_d.py")
1. Далее запускается алгоритм обучения. ( см. файл: "train.py" ) Работа алогритма : 
	- алгоритм подхватывает модель из папки "\MODEL\define_model.py" + конфиги с обучением хранятся в файле "\MODEL\config.py"
	- получает данные из DataLoader ( путь к итератору ) 
	- обучение
	- записывает веса модели в папку  "\weights\DD_MM_YYYY"
	- все графики обучения модели хранятся в "\reports\studies\DD_MM_YYYY\" 
	
1. Проверка модели запускается "test.py". Тестируются данные по всему датафрейму из папки "\data\3. final\" (train_dataset + validation_dataset), данные получаются из  DataLoader ( путь к итератору ) 
1. Все результаты теста хранятся в папке "\reports\studies\DD_MM_YYYY\"
1. Все презентации и отчеты хранятся в папке "\reports\"
1. скрипт для загрузки в БД для стенда хранится в корне "\upload.py"




## Скрипт для создания датасета для обучения линейной и lstm моделей
Скрип позволит:
* ПОДГОТОВКА ДАННЫХ
    -  Чтение исходных данных из папки "\data\1. external\"
    -  Создаем preprocessed данные "\data\2. preprocessed\" (stage.npy contractor.npy и тд )
    -  Преобразуем полученные данные "\data\3. final\" (в нужный вид (proj_id, contr_id, PO, month, year, res_id) len = 378) и сохранение в npy 
	+ или чтение данных сразу "\data\3. final\"
* СОЗДАНИЕ БД
    -  добавляем статистику за 3 месяца

## Необходимые данные для создания датасета:
* в папке "data\Needed_materials" должны лежать следующие файлы:
    - mech_missed_ids.xlsx
    - Norms.xlsx
    - Проекты ГСП.xls

## Запуск main.py:
- Прописать все пути и флаги (смотри описание флагов ниже)
    - Если уже есть файл DATA.xlsx (собранный файл для обучения), то только указать путь(PATH_TO_PROJECTS) до него
    - Если надо создать датасет нужно указать путь(PATH_TO_SAVE_TARGETS) до target_array.npy и путь(PATH_NPY_PROJECTS) до всех npy проектов.
    - Если нет npy проектов, то либо конвертируем уже имеющиеся xlsx проекты, указав путь(PATH_EXCEL_PROJECTS), либо выгружаем из БД и возводим флаг CONNECT:
        - можно выгрузить отдельный/ые проект/ы из БД, указав PROJ_ID (можно один, можно несколько через ",")
        - можно выгрузить все проекты из БД, возведя флаг DOWNLOAD_ALL_PROJECTS_FROM_DB
    - .юююю

### Описание флагов:
    -t (--PATH_TO_TARGETS_EXCEL):str - путь до exel данных с путевого листа. По умолчанию = 'data/targets_excel/'
    -s (--PATH_TO_SAVE_TARGETS):str - путь куда сохранить обработанные данные путевого листа. По умолчанию = 'data/'
    -j (--PATH_TO_PROJECTS):str - путь куда сохранить собранный датасет. По умолчанию = 'data/'
    -p (--PATH_EXCEL_PROJECTS):str - путь до выгруженных exel проектов с БД. По умолчанию = 'data/features/'
    -n (--PATH_NPY_PROJECTS):str - путь куда сохранять npy проекты после конвертации. По умолчанию = 'data/prepred_train_data/'
    -w (--SAVE_WEIGHT):str - путь куда сохранять веса модели после обучения.  По умолчанию = 'data/WEIGHTS/'
    -d (--DOP_DATA_PATH):str - путь куда сохранять дополнительные данные 
        (такие как: feature_contractor_dict.npy,mech_res_dict.npy, targets_contractors_dict.npy ...) для создания датасета. 
        По умолчанию = 'data/dop_materials/'

    -c (--CONNECT):int - если нужно сделать выгрузку проеката из БД = 1, иначе = 0. По умолчанию = 0
    -i (--PROJ_ID):str - идентификаторы проектов, который надо выгрузить из БД. По умолчанию = 32159
    -l (--DOWNLOAD_ALL_PROJECTS_FROM_DB):int - если выгружать все проекты (id_project берется из stages.xlsx) из БД = 1, иначе = 0.
    -r (--RELOAD_DOPS):int - если нужно создать\обновить(после загрузки из бд новго объекта) дополнительные данные = 1, иначе = 0.
       По умолчанию = 0
    -v (--CONVERT):int - если нужно конвертировать проекты из xlsx в npy = 1, иначе = 0. По умолчанию = 0
    -g (--TARGET):int - если нужно создать файл npy с таргетом по проектам = 1, иначе = 0 и в PATH_TO_SAVE_TARGETS указать путь до 
       target_array.npy. По умолчанию = 0
    -a (--CREATE_DATASET):int - если нужно создать датасет = 1 (при этом должен быть указан путь до target_array.npy
       и путь для всех npy проектов из которых составлять датасет), иначе = 0.  
    -z (--ADD_STATISTIC):int - если создавать датасет со статистикой 3 месяца = 1, иначе = 0.
    


    












